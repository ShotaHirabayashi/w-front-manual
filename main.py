# __import__('pysqlite3')
# import sys
# sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import streamlit as st
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma

# Streamlitã®è¨­å®š
st.set_page_config(page_title="Wãƒ•ãƒ­ãƒ³ãƒˆãƒãƒ‹ãƒ¥ã‚¢ãƒ«", layout="wide")

# Streamlitã®UIæ§‹ç¯‰
st.title("ğŸ“„ Wãƒ•ãƒ­ãƒ³ãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
st.write("ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã«åŸºã¥ã„ãŸè³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# OpenAIã®è¨­å®š
embeddings_model = OpenAIEmbeddings(api_key=st.secrets['openai']['OPENAI_API_KEY'], model="text-embedding-3-small")


llm = ChatOpenAI(api_key=st.secrets['openai']['OPENAI_API_KEY'],
                 model="gpt-4o-mini", temperature=0, max_tokens=200, top_p=0)


db = Chroma(collection_name='wdb',persist_directory="./wdb", embedding_function=embeddings_model)

prompt = PromptTemplate(
    input_variables=["document_snippet", "question"],
    template="""
ã‚ãªãŸã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚è³ªå•è€…ã¯è³ªå•å½¢å¼ã§è³ªå•ã—ã¦ã“ãªã„å¯èƒ½æ€§ã‚‚ã‚ã‚Šã€æ–‡ç« ã‚’æ±²ã¿å–ã£ã¦ç›¸æ‰‹ãŒçŸ¥ã‚ŠãŸã„ã“ã¨ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ã¯ãƒ¬ã‚¸ãƒ£ãƒ¼ãƒ›ãƒ†ãƒ«ã®ãƒ•ãƒ­ãƒ³ãƒˆæ¥­å‹™ã«é–¢ã™ã‚‹ã‚‚ã®ã§ã™ã€‚ã§ãã‚‹é™ã‚Šãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰æƒ…å ±ã‚’èª­ã¿å–ã‚Šå›ç­”ã™ã‚‹æ„è­˜ã‚’ã‚‚ã£ã¦ãã ã•ã„ã€‚
ã‚‚ã—è¨˜è¼‰ã«ãªã„ã“ã¨ãŒå•ã‚ã‚ŒãŸå ´åˆã¯ã€ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€‚ã€ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚ãŸã ã—ã‚ã¾ã‚Šã«ã‚‚å¤šãã®è³ªå•ã«ã€Œã‚ã‹ã‚Šã¾ã›ã‚“ã€‚ã€ã¨ç­”ãˆã‚‹ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä¸è¦ªåˆ‡ã ã¨æ€ã‚ã‚Œã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚
æ–‡ç« ã¯é©åˆ‡ã«è¿”ç­”ã—ã€é©å½“ãªæ–‡ç« ã¯è¿”ç­”ã—ãªã„ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚

    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼š
    {document_snippet}

    è³ªå•ï¼š{question}

    ç­”ãˆï¼š
    """
)



# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆé–¢æ•°
def chatbot(question):
    question_embedding = embeddings_model.embed_query(question)
    document_snippet = db.similarity_search_by_vector(question_embedding, k=3)
    snippets = [doc.page_content for doc in document_snippet]
    snippets = "\n---\n".join(snippets)
    print(f'question: {question}')
    print(snippets)
    filled_prompt = prompt.format(document_snippet=snippets, question=question)
    response = llm.invoke(filled_prompt)
    return response.content, document_snippet

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
if "messages" not in st.session_state:
    st.session_state.messages = []

# éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•å…¥åŠ›
question = st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")
print(f'question: {question}')
if question:
    st.session_state.messages.append({"role": "user", "content": question})
    with st.chat_message("user"):
        st.markdown(question)

    # å›ç­”ç”Ÿæˆ
    response, document_snippet = chatbot(question)
    st.session_state.messages.append({"role": "assistant", "content": response})

    with st.chat_message("assistant"):
        st.markdown(response)
