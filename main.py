import streamlit as st
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma

# Streamlitã®è¨­å®š
st.set_page_config(page_title="Chatbot", layout="wide")

# OpenAIã®è¨­å®š
embeddings_model = OpenAIEmbeddings(api_key=st.secrets['openai']['OPENAI_API_KEY'], model="text-embedding-3-small")
llm = ChatOpenAI(api_key=st.secrets['openai']['OPENAI_API_KEY'], model="gpt-4o-mini")
db = Chroma(persist_directory="./wdb", embedding_function=embeddings_model)

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
template = """
ã‚ãªãŸã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
ã‚‚ã—è¨˜è¼‰ã«ãªã„ã“ã¨ãŒå•ã‚ã‚ŒãŸå ´åˆã¯ã€ã‚ã‹ã‚‰ãªã„ã“ã¨ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚

ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼š{document_snippet}

è³ªå•ï¼š{question}

ç­”ãˆï¼š
"""
prompt = PromptTemplate(input_variables=["document_snippet", "question"], template=template)


# ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆé–¢æ•°
def chatbot(question):
    question_embedding = embeddings_model.embed_query(question)
    document_snippet = db.similarity_search_by_vector(question_embedding, k=2)
    filled_prompt = prompt.format(document_snippet=document_snippet, question=question)
    response = llm.invoke(filled_prompt)
    return response.content


# Streamlitã®UIæ§‹ç¯‰
st.title("ğŸ“„ Wãƒ•ãƒ­ãƒ³ãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ")
st.write("ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã«åŸºã¥ã„ãŸè³ªå•å¿œç­”ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
if "messages" not in st.session_state:
    st.session_state.messages = []

# éå»ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•å…¥åŠ›
question = st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")

if question:
    st.session_state.messages.append({"role": "user", "content": question})
    with st.chat_message("user"):
        st.markdown(question)

    # å›ç­”ç”Ÿæˆ
    response = chatbot(question)
    st.session_state.messages.append({"role": "assistant", "content": response})

    with st.chat_message("assistant"):
        st.markdown(response)
